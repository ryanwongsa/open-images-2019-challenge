{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "from dataloader import get_dataloader\n",
    "from preprocess import transformer, img_transform, reverse_img_transform\n",
    "from models import RetinaNet\n",
    "from loss import FocalLoss\n",
    "from train import Trainer, load_components, LRFinder\n",
    "from inference import InferenceTransform\n",
    "from utils import Visualiser\n",
    "from callbacks import Callback\n",
    "import pickle\n",
    "import gc\n",
    "import json\n",
    "\n",
    "from apex import amp\n",
    "\n",
    "\n",
    "gc.collect(2)\n",
    "\n",
    "\n",
    "configs_dir = \"configs/baseline_human_labels_configs.json\"\n",
    "\n",
    "parameters = json.load(open(configs_dir,'r'))\n",
    "\n",
    "### ================================== 1. PARAMETERS ======================================\n",
    "\n",
    "hyper_params = parameters[\"hyperparams\"]\n",
    "dir_params = parameters[\"dirparams\"]\n",
    "project_params = parameters[\"projectconfig\"]\n",
    "\n",
    "project_name = project_params[\"project_name\"]\n",
    "experiment_name = project_params[\"experiment_name\"]\n",
    "\n",
    "### ============================== 2. INITIALISATIONS ===================================\n",
    "\n",
    "clsids_to_names = pickle.load(open(dir_params[\"clsids_to_names_dir\"],'rb'))\n",
    "clsids_to_idx = pickle.load(open(dir_params[\"clsids_to_idx_dir\"],'rb'))\n",
    "idx_to_cls_ids = {v: k for k, v in clsids_to_idx.items()}\n",
    "idx_to_names = {k: clsids_to_names[v] for k, v in idx_to_cls_ids.items()}\n",
    "\n",
    "\n",
    "### ============================== 3. DATALOADERS ===================================\n",
    "\n",
    "train_seq = iaa.Sequential([\n",
    "        iaa.Resize({\"height\": int(hyper_params[\"img_dim\"]*1.05), \"width\": int(hyper_params[\"img_dim\"]*1.05)}),\n",
    "        iaa.GammaContrast((0.9,1.1)),\n",
    "        iaa.Affine(rotate=(-5, 5), scale=(0.90, 1.10)),\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.CropAndPad(percent=(-0.05, 0.00)),\n",
    "        iaa.Resize({\"height\": hyper_params[\"img_dim\"], \"width\": hyper_params[\"img_dim\"]})\n",
    "    ])\n",
    "train_transform_fn = transformer(train_seq, img_transform)\n",
    "train_dl = get_dataloader(\n",
    "        dir_params[\"train_images_dir\"], dir_params[\"train_bbox_dir\"], \n",
    "        dir_params[\"train_idx_to_id_dir\"], clsids_to_idx,\n",
    "        train_transform_fn, hyper_params[\"bs\"], True, hyper_params[\"num_workers\"], True\n",
    "    )\n",
    "\n",
    "valid_seq = iaa.Sequential([\n",
    "        iaa.Resize({\"height\": hyper_params[\"img_dim\"], \"width\": hyper_params[\"img_dim\"]})\n",
    "    ])\n",
    "valid_transform_fn = transformer(valid_seq, img_transform)\n",
    "valid_dl = get_dataloader(\n",
    "        dir_params[\"valid_images_dir\"], \n",
    "        dir_params[\"valid_bbox_dir\"], \n",
    "        dir_params[\"valid_idx_to_id_dir\"], \n",
    "        clsids_to_idx, \n",
    "        valid_transform_fn, hyper_params[\"bs\"], False, hyper_params[\"num_workers\"], False\n",
    "    )\n",
    "\n",
    "### ======================================== 4. LOSS ===================================\n",
    "\n",
    "criterion = FocalLoss(\n",
    "        hyper_params[\"alpha\"], \n",
    "        hyper_params[\"gamma\"], \n",
    "        hyper_params[\"IoU_bkgrd\"], \n",
    "        hyper_params[\"IoU_pos\"], \n",
    "        hyper_params[\"regress_factor\"], \n",
    "        hyper_params[\"device\"]\n",
    "    )\n",
    "\n",
    "### ======================================== 5. MODEL ===================================\n",
    "\n",
    "retinanet = RetinaNet(\n",
    "        hyper_params[\"backbone\"], \n",
    "        hyper_params[\"num_classes\"],\n",
    "        hyper_params[\"ratios\"], \n",
    "        hyper_params[\"scales\"], \n",
    "        device=hyper_params[\"device\"], \n",
    "        pretrained = hyper_params[\"pretrained\"], \n",
    "        freeze_bn = hyper_params[\"freeze_bn\"],\n",
    "        prior=0.01, \n",
    "        feature_size=256, \n",
    "        pyramid_levels = [3, 4, 5, 6, 7],\n",
    "        criterion=criterion\n",
    "    )\n",
    "\n",
    "def set_parameter_requires_grad(model):\n",
    "        for name, param in model.named_parameters():\n",
    "            if (name.split('.')[0]) not in [\"fpn\", \"regressionModel\", \"classificationModel\"]:\n",
    "                param.requires_grad = False\n",
    "\n",
    "if hyper_params[\"fine_tune\"]==True:\n",
    "    set_parameter_requires_grad(retinanet)\n",
    "retinanet = retinanet.to(hyper_params[\"device\"])\n",
    "\n",
    "### ==================================== 5. OPTIMIZER ===================================\n",
    "\n",
    "optimizer = optim.SGD(retinanet.parameters(), lr=0.00001, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "        mode='min', \n",
    "        factor=hyper_params['decay_factor'], \n",
    "        patience=hyper_params[\"patience\"], \n",
    "        verbose=True, \n",
    "        min_lr=hyper_params[\"min_lr\"]\n",
    "    )\n",
    "\n",
    "### ================================ 6. VISUALISATION ===================================\n",
    "\n",
    "vis = Visualiser(\n",
    "        hyper_params[\"num_classes\"],\n",
    "        idx_to_names,\n",
    "        reverse_img_transform\n",
    "    )\n",
    "\n",
    "### ================================ 7. INFERENCE ===================================\n",
    "\n",
    "inferencer = InferenceTransform(\n",
    "        idx_to_names,\n",
    "        idx_to_cls_ids,\n",
    "        hyper_params[\"regress_factor\"]\n",
    "    ) \n",
    "\n",
    "### =============================== 8. PREPARE TRAINING ================================\n",
    "\n",
    "load_components(retinanet, optimizer, scheduler, hyper_params[\"checkpoint_dir\"])\n",
    "# retinanet, optimizer = amp.initialize(retinanet, optimizer, opt_level=\"O1\")\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using Multiple GPUs\")\n",
    "    retinanet = torch.nn.DataParallel(retinanet, device_ids=range(torch.cuda.device_count())) \n",
    "retinanet = retinanet.to(hyper_params[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder = LRFinder(retinanet, optimizer, criterion, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_finder.range_test(train_dl, end_lr=100, num_iter=1000, step_mode=\"exp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
