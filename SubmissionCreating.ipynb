{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "import torch\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "from dataloader import get_test_dataloader\n",
    "from preprocess import transformer, img_transform, reverse_img_transform\n",
    "from models import RetinaNet\n",
    "from train import load_components\n",
    "from inference import InferenceTransform\n",
    "from utils import Visualiser\n",
    "import pickle\n",
    "import gc\n",
    "import json\n",
    "from evaluation import support_evaluate_model\n",
    "from collections import defaultdict\n",
    "gc.collect(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_inference(test_dl, config_dir, list_results_dict):\n",
    "    parameters = json.load(open(config_dir,'r'))\n",
    "\n",
    "    hyper_params = parameters[\"hyperparams\"]\n",
    "    dir_params = parameters[\"dirparams\"]\n",
    "    project_params = parameters[\"projectconfig\"]\n",
    "\n",
    "    clsids_to_names = json.load(open(dir_params[\"clsids_to_names_dir\"],'r'))\n",
    "    clsids_to_idx = json.load(open(dir_params[\"clsids_to_idx_dir\"],'r'))\n",
    "    idx_to_cls_ids = {v: k for k, v in clsids_to_idx.items()}\n",
    "    idx_to_names = {k: clsids_to_names[v] for k, v in idx_to_cls_ids.items()}\n",
    "\n",
    "    retinanet = RetinaNet(\n",
    "            hyper_params[\"backbone\"], \n",
    "            hyper_params[\"num_classes\"],\n",
    "            hyper_params[\"ratios\"], \n",
    "            hyper_params[\"scales\"], \n",
    "            device=hyper_params[\"device\"], \n",
    "            pretrained = hyper_params[\"pretrained\"], \n",
    "            freeze_bn = hyper_params[\"freeze_bn\"],\n",
    "            prior=0.01, \n",
    "            feature_size=256, \n",
    "            pyramid_levels = [3, 4, 5, 6, 7],\n",
    "            criterion=None\n",
    "        )\n",
    "    retinanet = retinanet.to(hyper_params[\"device\"])\n",
    "\n",
    "    vis = Visualiser(\n",
    "            hyper_params[\"num_classes\"],\n",
    "            idx_to_names,\n",
    "            reverse_img_transform\n",
    "        )\n",
    "\n",
    "    inferencer = InferenceTransform(\n",
    "            idx_to_names,\n",
    "            idx_to_cls_ids,\n",
    "            hyper_params[\"regress_factor\"]\n",
    "        ) \n",
    "\n",
    "    load_components(retinanet, None, None, hyper_params[\"save_dir\"]+\"/final.pth\")\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using Multiple GPUs\")\n",
    "        retinanet = torch.nn.DataParallel(retinanet, device_ids=range(torch.cuda.device_count())) \n",
    "    retinanet = retinanet.to(hyper_params[\"device\"])\n",
    "\n",
    "    eval_params = {\n",
    "        \"overlap\":hyper_params[\"overlap\"],\n",
    "        \"cls_thresh\": 0.05\n",
    "    }\n",
    "    \n",
    "    resultant_dict = support_evaluate_model(retinanet, \n",
    "       test_dl, \n",
    "       inferencer, \n",
    "       vis, \n",
    "       cls_thresh=eval_params[\"cls_thresh\"], \n",
    "       overlap=eval_params[\"overlap\"], \n",
    "       device=hyper_params[\"device\"], \n",
    "       save_dir=\"test\", \n",
    "       display = False, \n",
    "       create_result=True,\n",
    "       list_results_dict = list_results_dict)\n",
    "    \n",
    "    return resultant_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = iaa.Sequential([\n",
    "        iaa.Resize({\"height\": 640, \"width\": 640})\n",
    "    ])\n",
    "test_transform_fn = transformer(test_seq, img_transform)\n",
    "test_dl = get_test_dataloader(\n",
    "        \"dataset/test/test\", \n",
    "        \"data_info/test/test-idx_to_id.pkl\", \n",
    "        test_transform_fn, \n",
    "        16, \n",
    "        4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs_dir = [\n",
    "#     \"configs/final/subset0/1/config.json\",\n",
    "#     \"configs/final/subset1/0/config.json\",\n",
    "#     \"configs/final/subset2/0/config.json\",\n",
    "#     \"configs/final/subset3/3/config.json\",\n",
    "#     \"configs/final/subset4/5/config.json\",\n",
    "#     \"configs/final/subset5/4/config.json\",\n",
    "# ]\n",
    "configs_dir = [\n",
    "    \"configs/final/subset5/4/config.json\",\n",
    "    \"configs/final/subset0/2/config.json\",\n",
    "    \"configs/final/subset1/1/config.json\",\n",
    "    \"configs/final/subset2/1/config.json\",\n",
    "    \"configs/final/subset3/5/config.json\",\n",
    "    \"configs/final/subset4/7/config.json\",\n",
    "]\n",
    "out_file=\"submission2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from checkpoint: configs/final/subset5/4/final.pth\n",
      "Using Multiple GPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfdc7ddb0a564628b3d0872adf8d4213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading from checkpoint: configs/final/subset0/2/final.pth\n",
      "Using Multiple GPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4287cf004b2449c6bbe670f8d44ff06b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading from checkpoint: configs/final/subset1/1/final.pth\n",
      "Using Multiple GPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92785ce597374e209745792df1356aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading from checkpoint: configs/final/subset2/1/final.pth\n",
      "Using Multiple GPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daed2df78d214e2a894d7460e7c80558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading from checkpoint: configs/final/subset3/5/final.pth\n",
      "Using Multiple GPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc087f2fd52d479f9fd07734f0c5d75f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading from checkpoint: configs/final/subset4/7/final.pth\n",
      "Using Multiple GPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b18e224795b4a9a9bb53d81e13affc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "list_results_dict = defaultdict(list)\n",
    "for config_dir in configs_dir:\n",
    "    list_results_dict = perform_inference(test_dl, config_dir, list_results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c652695f0b83414a9bcb1af85ddbc703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=99999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "f = open(out_file,\"w+\")\n",
    "results=\"ImageId,PredictionString\\n\"\n",
    "f.write(results)\n",
    "for key, value in tqdm(list_results_dict.items()):\n",
    "    results=key+\",\"\n",
    "    for val in value:\n",
    "        clsId = val[0]\n",
    "        score = round(val[1],2)\n",
    "        bbox = ' '.join(str(round(e,5)) for e in val[2])\n",
    "        results+= str(clsId) + \" \"+ str(score)+ \" \" + bbox + \" \"\n",
    "    results +=\"\\n\"\n",
    "    f.write(results)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
